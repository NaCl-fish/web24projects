# 使用web信息增强的可控图像生成

# 									许怿芃2023103706

## Abstract

```
· 设置了一个新的图像生成场景，即通过相关资源或文本到图像模型，通过给定文本描述来获得基本图像，并生成与添加详细描述相一致的高质量图像。
· 在这种情况下，提出了一种基线方法，包括三个阶段：文本描述优化、基础图像获取和目标图像再生。
· 通过语言模型优化初始文本描述可以生成更有利于文本到图像生成模型的提示。通过检索或生成模型获得的图像与文本描述相匹配，以选择适当的基础图像。通过使用ControlNet，基线方法可以重新生成符合详细描述的图像，同时保留基本图像的轮廓。
```

## Motivation

```
· 扩散模型的出现标志着高质量图像生成的重大进展，使简单文本描述中的图像变得多样化和逼真。
· 虽然这些模型准确地捕捉了整体语义信息，但它们在属性级别的生成往往不足，甚至生成与输入提示不一致的细节。
· 借助web端的海量知识辅助图像生成，让生成任务聚焦更细粒度的特征。
```

![motivation](C:\Users\17616\Desktop\2023103706\image\motivation.png)

## Related Work

```
· 文生图
    通过将交叉注意层纳入扩散架构，潜在扩散将扩散模型修改为灵活的生成器，可适应各种类型的条件反射，例如文本输入。在这个工作中，使用从扩散模型生成的图像作为一个粗略的参考，其重点是关于图像轮廓的信息。
· 多模态控制
    使用边缘图、位姿图、草图、拖拽信息等多种形式与文本提示结合生成图像。相反，这个工作使用文本描述作为输入。ControlNet的基础图像是从图像生成或检索中获得的。
· 检索增强的生成
    已有一些基于检索信息增强图像生成的方法，但是大都停留在已有实体级别。这个工作的目标是在已有实体的基础上生成更细粒度的属性信息。
```

## Method

```
考虑人们使用模型从他们的想象中生成图像的场景，他们只需要为想象中的图像提供文本描述。通过文本优化，文本信息得到巩固和扩展，增强了描述，以作为检索的输入。当获得基础图像时，在相关图像集或真实世界图像中进行检索，或者可选地，以所提供的文本描述作为输入来执行基于扩散的生成。利用所选择的基础图像，基于文本描述对图像细节进行调整，从而产生与所提供的文本紧密对应的图像，同时保留参考图像的基本结构。
· 文本优化
文本描述通常包含复杂的信息，需要调整以适合作为基于扩散的生成模型的提示或作为检索的查询。假设目标图像的描述被表示为T，包括关键信息k1，k2，.，kn，n表示文本描述T中的关键信息的数量。通过利用适当的文本修饰符M，这些关键信息被整合以形成增强的描述d。根据现有的方法，设计了两种方法来设计文本修饰符：一种涉及手工制作的模板MP，另一种采用基于大型语言模型（LLM）ML的文本修饰符。在基于模板的方法中，关键信息k1，k2，...，kn被顺序地插入到模板MP中。
· 基础图像检索
在进行详细的图像生成之前，关键的一步是获取基本符合指定描述的基础图像。提出了一个基本的图像选择方法，符合自适应策略（AS）。当给出文本描述时，有两种方法可以获得相应的图像。一种方法涉及利用文本到图像合成模型，其中输入描述d以生成用作基础的图像。另一种方法涉及使用d作为用于检索的查询以获得基础图像。为了解决潜在的变化，在所获得的基础图像，提出了一个自适应的图像选择策略。
检索方法获得一个真实世界的图像IR。我们利用文本相似性来模拟检索图像的过程中的文本描述的基础上。对于给定的文本查询d，假设存在包含文本—图像对（texti，imagei）的集合D，其中i = 1，2，.，m，m表示文本—图像对的数量。通过文本编码器E，对描述d和texti进行编码以获得文本特征E（d）、E（texti）。在检索模式中，选择与具有最大相似度的文本描述匹配的图像作为基础图像Ir。
对于使用文本到图像合成模型S的生成方法，选择适当的参数θ。通过输入文本描述d，获得生成图像IG。
此外，采用了自适应策略来选择可用的基础图像。对于对应于文本d的基础图像集IB，使用文本编码器Et和图像编码器Ei来提取特征Et（d）、Ei（IB）。通过计算文本特征与每个图像特征之间的相似度，选择与给定文本最匹配的图像作为基础图像Ib。
· 目标图像生成
在得到参考图像后，首先利用Canny边缘检测算法提取参考图像的边缘图。然后通过ControlNet将边缘图与细节描述数据组合以获得目标图像。
```

![method](C:\Users\17616\Desktop\2023103706\image\method.png)

## Experiments

![experiments](C:\Users\17616\Desktop\2023103706\image\experiments.png)

![table](C:\Users\17616\Desktop\2023103706\image\table.png)

```
对两个数据集的结果进行评价。这里，t-SIM表示文本和图像之间的相似性，i-SIM表示图像与图像之间的相似性。AS表示我们的自适应策略，其中AS（l+t）只考虑基于生成的两种方法，而AS-all考虑所有方法。
```

## Conclusion

```
· 设置了一个新的图像生成场景，其中图像的生成仅需要用户给出包含详细描述的文本输入。
· 该方法在控制生成的图像的具体细节具有很好的性能，以及在数据稀缺的环境中具有一定程度的鲁棒性。
· 然而，选择基本图像的自适应策略和ControlNet的控制机制仍然存在讨论和增强的途径。
```

